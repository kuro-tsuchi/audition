<!-- ---
sidebar:  false
--- -->

# 1. redis

## 1.1. 简单介绍一下 Redis

Redis 是C语言开发的内存型数据库, 读写速度非常快, 常用做缓存.

此外, Redis 还经常用来做分布式锁(redission),甚至是消息队列. Redis 还支持事务,持久化,Lua 脚本,多种集群方案.


## 1.3. 分布式缓存作用

分布式缓存表示能跨越多台服务器，同时具有可扩展性的缓存

分布式缓存主要解决的是单机容量受限并且无法保存通用信息的问题.

## 1.5. 缓存数据的处理流程是怎样的?

![picture 1](../.vuepress/public/assets/images/1639830237323.png)

1. 如果用户请求的数据在缓存中就直接返回.
2. 缓存中不存在, 查看数据库中是否存在.
3. 数据库中存在, 更新缓存中的数据.
4. 数据库中不存在, 返回空数据.

## 1.6. 为什么要用 Redis(缓存)?

使用缓存主要是为了提升用户体验以及应对更多的用户.

### 1.6.1. 高性能

用户首次访问数据库中的某些数据是从硬盘中读取的,速度较慢,如果用户访问的数据属于高频数据并且不会经常改变的话,那么可以将用户访问的数据存在缓存中.保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了. 操作缓存就是直接操作内存,所以速度相当快.


### 1.6.2. 高并发

直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的,所以可以考虑把数据库中的部分数据转移到缓存中去, 也就提高了系统整体的并发.

> QPS(Query Per Second): 服务器每秒可以执行的查询次数;
> MySQL 数据库的 QPS 大概都在 1w 左右 (4 核 8g) , 但是使用 Redis 缓存之后很容易达到 10w+, 甚至最高能达到 30w+( 此为 redis 单机的情况,redis 集群的话会更高).

## 1.8. Redis 常见数据结构以及使用场景分析

### 1.8.1. string

1. 介绍: string 数据结构是简单的 key-value 类型
2. 常用命令:set, get, strlen, exists, decr, incr, setex 等等.
3. 应用场景:存储信息,计数器

#### 1.8.1.1. 普通字符串的基本操作

```bash
127.0.0.1: 6379> set key value #设置 key-value 类型的值
OK
127.0.0.1: 6379> get key # 根据 key 获得对应的 value
value
127.0.0.1: 6379> exists key  # 判断某个 key 是否存在
(integer) 1
127.0.0.1: 6379> strlen key # 返回 key 所储存的字符串值的长度.
(integer) 5
127.0.0.1: 6379> del key # 删除某个 key 对应的值
(integer) 1
127.0.0.1: 6379> get key
(nil)
```

#### 1.8.1.2. 批量设置

```bash
127.0.0.1: 6379> mset key1 value1 key2 value2 # 批量设置 key-value 类型的值
OK
127.0.0.1: 6379> mget key1 key2 # 批量获取多个 key 对应的 value
1) value1
2) value2
```

#### 1.8.1.3. 计数器 (字符串的内容为整数的时候可以使用)

```bash
127.0.0.1: 6379> set number 1
OK
127.0.0.1: 6379> incr number # 将 key 中储存的数字值增一
(integer) 2
127.0.0.1: 6379> get number
2
127.0.0.1: 6379> decr number # 将 key 中储存的数字值减一
(integer) 1
127.0.0.1: 6379> get number
1
```

#### 1.8.1.4. 过期 (默认为永不过期)

```bash
127.0.0.1: 6379> expire key  60 # 数据在 60s 后过期
(integer) 1
127.0.0.1: 6379> setex key 60 value # 数据在 60s 后过期 (setex: [set] + [ex]pire)
OK
127.0.0.1: 6379> ttl key # 查看数据还有多久过期
(integer) 56
```

### 1.8.2. list

1. 介绍 : list 即是 链表.链表是一种非常常见的数据结构,特点是易于数据元素的插入和删除并且可以灵活调整链表长度,但是链表的随机访问困难.
2. 常用命令:rpush, lpop, lpush, rpop, lrange, llen 等.
3. 应用场景:发布与订阅或者说消息队列,慢查询.

#### 1.8.2.1. 通过 rpush/lpop 实现队列

```bash
127.0.0.1: 6379> rpush myList value1 # 向 list 的头部 (右边) 添加元素
(integer) 1
127.0.0.1: 6379> rpush myList value2 value3 # 向 list 的头部 (最右边) 添加多个元素
(integer) 3
127.0.0.1: 6379> lpop myList # 将 list 的尾部 (最左边) 元素取出
value1
127.0.0.1: 6379> lrange myList 0 1 # 查看对应下标的 list 列表,0 为 start, 1 为 end
1) value2
2) value3
127.0.0.1: 6379> lrange myList 0 -1 # 查看列表中的所有元素,-1 表示倒数第一
1) value2
2) value3
```

#### 1.8.2.2. 通过 rpush/rpop 实现栈

```bash
127.0.0.1: 6379> rpush myList2 value1 value2 value3
(integer) 3
127.0.0.1: 6379> rpop myList2 # 将 list 的头部 (最右边) 元素取出
value3
```

![picture 3](../.vuepress/public/assets/images/1639832056184.png)  

#### 1.8.2.3. 通过 lrange 查看对应下标范围的列表元素

```bash
127.0.0.1: 6379> rpush myList value1 value2 value3
(integer) 3
127.0.0.1: 6379> lrange myList 0 1 # 查看对应下标的 list 列表,0 为 start, 1 为 end
1) value1
2) value2
127.0.0.1: 6379> lrange myList 0 -1 # 查看列表中的所有元素,-1 表示倒数第一
1) value1
2) value2
3) value3
```

通过 lrange 命令,你可以基于 list 实现分页查询,性能非常高!

#### 1.8.2.4. 通过 llen 查看链表长度

```bash
127.0.0.1: 6379> llen myList
(integer) 3
```

### 1.8.3. hash

1. hash 是一个 string 类型的 field 和 value 的映射表,特别适合用于存储对象
2. 常用命令:hset, hmset, hexists, hget, hgetall, hkeys, hvals 等.

```bash
127.0.0.1: 6379> hmset userInfoKey name guide description dev age 24
OK
127.0.0.1: 6379> hexists userInfoKey name # 查看 key 对应的 value 中指定的字段是否存在.
(integer) 1
127.0.0.1: 6379> hget userInfoKey name # 获取存储在哈希表中指定字段的值.
guide
127.0.0.1: 6379> hget userInfoKey age
24
127.0.0.1: 6379> hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值
1) name
2) guide
3) description
4) dev
5) age
6) 24
127.0.0.1: 6379> hkeys userInfoKey # 获取 key 列表
1) name
2) description
3) age
127.0.0.1: 6379> hvals userInfoKey # 获取 value 列表
1) guide
2) dev
3) 24
127.0.0.1: 6379> hset userInfoKey name GuideGeGe # 修改某个字段对应的值
127.0.0.1: 6379> hget userInfoKey name
GuideGeGe
```

### 1.8.4. set

1. 介绍 :  Redis 中的 set 类型是一种无序集合, 底层使用了 intset 和 hashtable 两种数据结构存储的
2. 常用命令:sadd, spop, smembers, sismember, scard, sinterstore, sunion 等.

```bash
127.0.0.1: 6379> sadd mySet value1 value2 # 添加元素进去
(integer) 2
127.0.0.1: 6379> sadd mySet value1 # 不允许有重复元素
(integer) 0
127.0.0.1: 6379> smembers mySet # 查看 set 中所有的元素
1) value1
2) value2
127.0.0.1: 6379> scard mySet # 查看 set 的长度
(integer) 2
127.0.0.1: 6379> sismember mySet value1 # 检查某个元素是否存在 set 中,只能接收单个元素
(integer) 1
127.0.0.1: 6379> sadd mySet2 value2 value3
(integer) 2
127.0.0.1: 6379> sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中
(integer) 1
127.0.0.1: 6379> smembers mySet3
1) value2
```

### 1.8.5. zset (sorted set)

1. 介绍:和 set 相比,sorted set 增加了一个权重参数 score,使得集合中的元素能够按 score 进行有序排列,还可以通过 score 的范围来获取元素的列表.
2. 常用命令:zadd, zcard, zscore, zrange, zrevrange, zrem 等.

```bash
127.0.0.1: 6379> zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重
(integer) 1
127.0.0.1: 6379> zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素
(integer) 2
127.0.0.1: 6379> zcard myZset # 查看 sorted set 中的元素数量
(integer) 3
127.0.0.1: 6379> zscore myZset value1 # 查看某个 value 的权重
3
127.0.0.1: 6379> zrange  myZset 0 -1 # 顺序输出某个范围区间的元素,0 -1 表示输出所有元素
1) value3
2) value2
3) value1
127.0.0.1: 6379> zrange  myZset 0 1 # 顺序输出某个范围区间的元素,0 为 start  1 为 stop
1) value3
2) value2
127.0.0.1: 6379> zrevrange  myZset 0 1 # 逆序输出某个范围区间的元素,0 为 start  1 为 stop
1) value1
2) value2
```

## 1.10. Redis 没有使用多线程?

1. 单线程编程和维护容易;
2. Redis 的性能瓶颈不在 CPU , 主要在内存和网络;
3. 多线程就会存在死锁,线程上下文切换等问题,甚至会影响性能.

## 1.11. Redis 给缓存数据设置过期时间有啥用?

内存是有限的,如果缓存中的所有数据都是一直保存的话, 会导致内存不足.

Redis 自带了给缓存数据设置过期时间的功能,比如:

```bash
127.0.0.1: 6379> exp key 60 # 数据在 60s 后过期
(integer) 1
127.0.0.1: 6379> setex key 60 value # 数据在 60s 后过期 (setex: [set] + [ex]pire)
OK
127.0.0.1: 6379> ttl key # 查看数据还有多久过期
(integer) 56
```

注意: Redis 中除了字符串类型有自己独有设置过期时间的命令 setex 外,其他方法都需要依靠 expire 命令来设置过期时间 .另外,persist 命令可以移除一个键的过期时间.

### 1.11.1. 过期时间除了有助于缓解内存的消耗,还有什么其他用么?

很多时候业务场景需要某个数据只在某一时间段内存在,比如短信验证码可能只在 1 分钟内有效,用户登录的 token 可能只在 1 天内有效. 如果使用传统的数据库来处理的话,一般都是自己判断过期,这样更麻烦并且性能要差很多.

## 1.13. redis 过期数据的删除策略?

### 1.13.1. 常用的过期数据的删除策略

1. 惰性删除:取出 key 的时候才对数据进行过期检查.
2. 定期删除:每隔一段时间抽取一批 key 检查过期时间, 删除过期 key. 

定期删除对内存更加友好,惰性删除对 CPU 更加友好.两者各有千秋,所以 Redis 采用的是 定期删除 + 惰性删除 .

> 但是,仅仅通过给 key 设置过期时间, 可能存在漏掉很多过期 key 的情况. 这样就导致大量过期 key 堆积在内存里, 导致内存不足. 需要使用 redis 内存淘汰机制.

## 1.14. Redis 内存淘汰机制了解么?(缓存如何回收?)

1. allkeys-lru(least recently used): 当内存不足以容纳新写入数据时,在键空间中,移除最近最少使用的 key(这个是最常用的, 最少使用的回收)
1. volatile-lru(least recently used): 从已设置过期时间的数据集 (server.db[i].expires) 中挑选最近最少使用的数据淘汰
1. volatile-ttl: 从已设置过期时间的数据集 (server.db[i].expires) 中挑选将要过期的数据淘汰
1. volatile-random: 从已设置过期时间的数据集 (server.db[i].expires) 中任意选择数据淘汰
1. allkeys-random: 从数据集 (server.db[i].dict) 中任意选择数据淘汰
1. no-eviction: 禁止驱逐数据,也就是说当内存不足以容纳新写入数据时,新写入操作会报错.这个应该没人使用吧!

## 1.15. MySQL 里有 2000w 数据,Redis 中只存 20w 的数据,如何保证 Redis 中的数据都是热点数据?

可以使用allkeys-lru内存淘汰策略, 该策略从 Redis 的数据中挑选最近最少使用的数据删除,这样频繁被访问的数据就可以保留下来了.

## 1.16. Redis 持久化机制? Redis崩溃后，如何进行数据恢复?

持久化数据就是将缓存中的数据保存到数据库, 主要原因是为了重新使用数据 (比如重启机器,机器故障之后恢复数据)

Redis 支持两种不同的持久化操作. 快照 (snapshotting, RDB) 和只追加文件 (append-only file,  AOF).

### 1.16.1. 快照持久化(默认)

Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本. Redis 创建快照之后,可以对快照进行备份,可以将快照复制到其他服务器从而创建具有相同数据的服务器副本

### 1.16.2. AOF持久化 (主流方案)

开启 AOF 持久化后, 每执行一条会更改 Redis 中的数据的命令,Redis 就会将该命令写入到内存缓存 server.aof_buf 中,然后再根据 appendfsync 的配置来决定何时将其同步到硬盘中的 AOF 文件.

## 1.17. Redis 事务

Redis 可以通过 MULTI, EXEC, DISCARD 和 WATCH 等命令来实现事务 (transaction) 功能.

```bash
> MULTI
OK
> SET USER Guide 哥
QUEUED
> GET USER
QUEUED
> EXEC
1) OK
2) Guide 哥
```

使用 MULTI 命令后可以输入多个命令. Redis 不会立即执行这些命令,而是将它们放到队列,当调用了 EXEC 命令将执行所有命令.

1. 开始事务 (MULTI).
2. 命令入队 (批量操作 Redis 的命令,先进先出 (FIFO) 的顺序执行).
3. 执行事务 (EXEC).

你也可以通过 [DISCARD]命令取消一个事务,它会清空事务队列中保存的所有命令.

```bash
> MULTI
OK
> SET USER Guide 哥
QUEUED
> GET USER
QUEUED
> DISCARD
OK
```

[WATCH]命令用于监听指定的键,当调用 EXEC 命令执行事务时,如果一个被 WATCH 命令监视的键被修改的话,整个事务都不会执行,直接返回失败.

```bash
> WATCH USER
OK
> MULTI
> SET USER Guide 哥
OK
> GET USER
Guide 哥
> EXEC
ERR EXEC without MULTI
```

但是,Redis 的事务和关系型数据库的事务不同,Redis 事务提供了一种将多个命令请求打包的功能.然后,再按顺序执行打包的所有命令,并且不会被中途打断

Redis 是不支持 roll back 的,因而不满足原子性的 (而且不满足持久性)

## 1.18. 缓存穿透

### 1.18.1. 什么是缓存穿透?

大量请求的 key 不存在于缓存中, 请求直接到了数据库上

> e.g. 某个黑客故意制造缓存中不存在的 key 发起大量请求,导致大量请求落到数据库.

### 1.18.2. 如何避免缓存穿透 ?

#### 1.18.2.1. 参数校验

一些不合法的参数请求直接抛出异常信息返回给客户端

> 比如查询的数据库 id 不能小于 0,传入的邮箱格式不对的时候直接返回错误消息给客户端等等.

#### 1.18.2.2. 缓存无效 key

如果缓存和数据库都查不到某个 key 的数据, 缓存key到 Redis 中去并设置过期时间, 过期时间设置短一点比如 1 分钟, 可以避免大量无效key占用内存

#### 1.18.2.3. 布隆过滤器

布隆过滤器可以非常方便地判断一个给定数据是否存在于海量数据中.

布隆过滤器说某个元素存在,小概率会误判. 布隆过滤器说某个元素不存在,那么这个元素一定不存在.

##### 1.18.2.3.1. 原理

当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个位数组中的 K 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：如果这些点有任何一个 0，则被检元素一定不在；如果都是 1，则被检元素很可能在。这就是布隆过滤器的基本思想。

![picture 13](../.vuepress/public/assets/images/1640438603085.png)  

把所有可能存在的请求的值都存放在布隆过滤器中,当用户请求过来,先判断用户发来的请求的值是否存在于布隆过滤器中.不存在的话,直接返回请求参数错误信息给客户端,存在的话才会继续走流程.

## 1.19. 缓存击穿

一个热点 Key，在某些时间点被超高并发地访问，key 突然过期失效了, 缓存没有则会去数据库请求, 引发数据库压力剧增

### 1.19.1. 缓存失效处理方案

1. 通过互斥锁或者队列来控制读数据写缓存的线程数量,比如某个key只允许一个线程查询数据和写缓存,其他线程等待.这种方式会阻塞其他的线程,此时系统的吞吐量会下降
1. 热点数据缓存永远不过期.

## 1.20. 缓存雪崩

### 1.20.1. 什么是缓存雪崩?

当同一个时刻出现大规模的缓存key失效，导致大量的请求直接打在数据库，在高并发的情况下，可能瞬间就会导致数据库宕机。

> 举个例子:系统的缓存模块出了问题比如宕机导致不可用.造成系统的所有访问,都要走数据库.
>
> 还有一种缓存雪崩的场景是:有一些被大量访问数据 (热点缓存) 在某一时刻大面积失效,导致对应的请求直接落到了数据库上.
>
> 举个例子 : 秒杀开始 12 个小时之前,统一存放了一批商品到 Redis 中,设置的缓存过期时间也是 12 个小时,那么秒杀开始的时候,这些秒杀的商品的访问直接就失效了.导致的情况就是,相应的请求直接就落到了数据库上,就像雪崩一样可怕.

### 1.20.2. 解决方案

#### 1.20.2.1. 事前

1. 均匀过期:设置不同的过期时间,让缓存失效的时间尽量均匀,避免相同的过期时间导致缓存雪崩,造成大量数据库的访问.
1. 分级缓存:第一级缓存失效的基础上,访问二级缓存,每一级缓存的失效时间都不同.
1. 热点数据缓存永远不过期.
1. 保证Redis缓存的高可用,防止Redis宕机导致缓存雪崩的问题.可以使用 主从+ 哨兵,Redis集群来避免 Redis 全盘崩溃的情况.

#### 1.20.2.2. 事中

1. 互斥锁:在缓存失效后,通过互斥锁或者队列来控制读数据写缓存的线程数量,比如某个key只允许一个线程查询数据和写缓存,其他线程等待.这种方式会阻塞其他的线程,此时系统的吞吐量会下降
1. 使用熔断机制,限流降级.当流量达到一定的阈值,直接返回"系统拥挤"之类的提示,防止过多的请求打在数据库上将数据库击垮,至少能保证一部分用户是可以正常使用,其他用户多刷新几次也能得到结果.

#### 1.20.2.3. 事后

开启Redis持久化机制,尽快恢复缓存数据,一旦重启,就能从磁盘上自动加载数据恢复内存中的数据.

### 1.20.3. 有哪些解决办法?

#### 1.20.3.1. 针对 Redis 服务不可用的情况

1. 采用 Redis 集群,避免单机出现问题整个缓存服务都没办法使用.
2. 限流,避免同时处理大量的请求.

#### 1.20.3.2. 针对热点缓存失效的情况

1. 设置不同的失效时间比如随机设置缓存的失效时间.
2. 缓存永不失效.

## 1.21. 缓存预热

缓存预热就是系统上线或更新后，提前将相关配置的缓存数据直接加载到缓存系统。避免在网站用户在系统上线第一次请求的时候，先查询数据库，然后再将数据缓存的问题 ,减少了数据库的压力

## 1.22. Redis与MySQL双写一致性问题如何解决?

理论上给缓存设置过期时间,是保证最终一致性的解决方案, 但是会占用大量的 CPU 资源去处理过期的数据，从而影响缓存的响应和吞吐量。

### 1.22.1. 四种更新策略

1. 先更新缓存,再更新数据库.
1. 先更新数据库,再更新缓存
1. 先删除缓存,再更新数据库
1. 先更新数据库,再删除缓存

### 1.22.2. 先更新缓存,再更新数据库 (pass)

更新完缓存后,数据库由于某种原因宕机了,直接 pass 掉.

### 1.22.3. 先更新数据库,再更新缓存 (pass)

#### 1.22.3.1. 多线程场景

同时有请求 A 和请求 B 进行更新操作,那么会出现 1)线程 A 更新了数据库; 2)线程 B 更
新了数据库; 3)线程 B 更新了缓存; 4)线程 A 更新了缓存; 这就出现请求 A 更新缓存应
该比请求 B 更新缓存早才对,但是因为网络等原因,B 却比 A 更早更新了缓存.这就导致了
脏数据,直接 pass 掉.

#### 1.22.3.2. 业务场景

1. 如果是一个写数据库场景比较多,而读数据场景比较少的业务需求,采用这种方案就会导
   致,数据压根还没读到,缓存就被频繁的更新,浪费性能.
1. 如果写入数据库的值,并不是直接写入缓存的,而是要经过一系列复杂的计算再写入缓存.
   那么,每次写入数据库后,都再次计算写入缓存的值,无疑是浪费性能的.显然,删除缓存更
   为适合.

### 1.22.4. 先删除缓存,再更新数据库(pass)

该方案会导致不一致的原因是:同时有一个请求 A 进行更新操作,另一个请求 B 进行查询操
作.

1. 请求 A 进行写操作,删除缓存;
1. 请求 B 查询发现缓存不存在;
1. 请求 B 去数据库查询得到旧值;
1. 请求 B 将旧值写入缓存;
1. 请求 A 将新值写入数据库; 上述情况就会导致不一致的情形出现.而且,如果不采用给缓
   存设置过期时间策略,该数据永远都是脏数据.

### 1.22.5. 先更新数据库,再删除缓存

这种情况也会存在并发问题: 假设有两个请求,一个请求 A 做查询操作,一个请求 B 做更新
操作,那么会有如下情形产生:

1. 缓存刚好失效;
1. 请求 A 查询数据库,得一个旧值;
1. 请求 B 将新值写入数据库;
1. 请求 B 删除缓存;(只是删除动作)
1. 请求 A 将查到的旧值写入缓存; 如果发生上述情况,确实是会发生脏数据.

然而,发生这种情况的概率又有多少呢? 发生上述情况有一个先天性条件,就是步骤(3)的写
数据库操作比步骤(2)的读数据库操作耗时更短,才有可能使得步骤(4)先于步骤(5).可是,数
据库的读操作的速度远快于写操作的,因此步骤(3)耗时比步骤(2)更短,这一情形很难出现.

#### 1.22.5.1. 在写数据的过程中,可以先删除 cache ,后更新 DB 么

不行, 先删除 cache, 再更新 DB 可能会造成数据库(DB)和缓存(Cache)数据不一致的问题, 容易产生脏数据

两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏数据, 脏数据在重新写数据前会一直存在
