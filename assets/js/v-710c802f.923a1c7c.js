"use strict";(self.webpackChunkaudition=self.webpackChunkaudition||[]).push([[448],{8796:(e,r,l)=>{l.r(r),l.d(r,{data:()=>a});const a={key:"v-710c802f",path:"/mq/rocketmq.html",title:"1. RocketMQ",lang:"en-EN",frontmatter:{},excerpt:"",headers:[{level:2,title:"1.1. RocketMQ 是什么？",slug:"_1-1-rocketmq-是什么",children:[{level:3,title:"1.1.1. RocketMQ 中的消息模型",slug:"_1-1-1-rocketmq-中的消息模型",children:[]},{level:3,title:"1.1.2. 每个消费者组在每个队列上维护一个消费位置 ,  为什么呢？",slug:"_1-1-2-每个消费者组在每个队列上维护一个消费位置-为什么呢",children:[]},{level:3,title:"1.1.3. 为什么一个主题中需要维护多个队列 ?",slug:"_1-1-3-为什么一个主题中需要维护多个队列",children:[]}]},{level:2,title:"1.2. RocketMQ 的架构图",slug:"_1-2-rocketmq-的架构图",children:[{level:3,title:"1.2.1. Broker",slug:"_1-2-1-broker",children:[]},{level:3,title:"1.2.2. NameServer",slug:"_1-2-2-nameserver",children:[]},{level:3,title:"1.2.3. Producer",slug:"_1-2-3-producer",children:[]},{level:3,title:"1.2.4. Consumer",slug:"_1-2-4-consumer",children:[]},{level:3,title:"1.2.5. 架构原理",slug:"_1-2-5-架构原理",children:[]}]},{level:2,title:"1.3. 如何解决顺序消费，重复消费",slug:"_1-3-如何解决顺序消费-重复消费",children:[{level:3,title:"1.3.1. 顺序消费",slug:"_1-3-1-顺序消费",children:[]},{level:3,title:"1.3.2. 重复消费 (幂等)",slug:"_1-3-2-重复消费-幂等",children:[]}]},{level:2,title:"1.4. rocketmq 如何保证消息不丢失",slug:"_1-4-rocketmq-如何保证消息不丢失",children:[{level:3,title:"1.4.1. 从 Producer 分析：如何确保消息正确的发送到了 Broker?",slug:"_1-4-1-从-producer-分析-如何确保消息正确的发送到了-broker",children:[]},{level:3,title:"1.4.2. 从 Broker 分析：如果确保接收到的消息不会丢失？",slug:"_1-4-2-从-broker-分析-如果确保接收到的消息不会丢失",children:[]},{level:3,title:"1.4.3. 从 Cunmser 分析：如何确保拉取到的消息被成功消费？",slug:"_1-4-3-从-cunmser-分析-如何确保拉取到的消息被成功消费",children:[]}]},{level:2,title:"1.5. 消息堆积问题 (削峰)",slug:"_1-5-消息堆积问题-削峰",children:[{level:3,title:"1.5.1. 解决消息堆积问题的方法",slug:"_1-5-1-解决消息堆积问题的方法",children:[]}]},{level:2,title:"1.6. 回溯消费",slug:"_1-6-回溯消费",children:[]},{level:2,title:"1.7. RocketMQ 的刷盘机制",slug:"_1-7-rocketmq-的刷盘机制",children:[{level:3,title:"1.7.1. 同步刷盘和异步刷盘",slug:"_1-7-1-同步刷盘和异步刷盘",children:[]},{level:3,title:"1.7.2. 同步复制和异步复制",slug:"_1-7-2-同步复制和异步复制",children:[]}]}],filePathRelative:"mq/rocketmq.md",git:{updatedTime:1646088479e3,contributors:[{name:"shorestraydog",email:"shorestraydog@protonmail.com",commits:9}]}}},1635:(e,r,l)=>{l.r(r),l.d(r,{default:()=>Fe});var a=l(6252),n=l(553),o=l(7716),t=l(8086),i=l(4637),_=l(9480),u=l(3400),c=l(9141),s=l(8354),d=l(9324),h=l(3333),k=l(3900),p=l(2128);const m=(0,a._)("h1",{id:"_1-rocketmq",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-rocketmq","aria-hidden":"true"},"#"),(0,a.Uk)(" 1. RocketMQ")],-1),g=(0,a._)("h2",{id:"_1-1-rocketmq-是什么",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-1-rocketmq-是什么","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.1. RocketMQ 是什么？")],-1),b=(0,a._)("p",null,"RocketMQ 是一个队列模型的消息中间件，具有高性能，高可靠，高实时，分布式的特点。它是一个采用 Java 语言开发的分布式的消息系统，由阿里巴巴团队开发，在 2016 年底贡献给 Apache",-1),f=(0,a._)("h3",{id:"_1-1-1-rocketmq-中的消息模型",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-1-1-rocketmq-中的消息模型","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.1.1. RocketMQ 中的消息模型")],-1),B=(0,a._)("p",null,[(0,a._)("img",{src:n,alt:"picture 1"})],-1),v=(0,a._)("blockquote",null,[(0,a._)("p",null,"主题模型/发布订阅模型就是一个标准，中间件照着这个标准去实现。每个消息中间件的底层设计都是不一样的，就比如 Kafka 中的分区 , RocketMQ 中的队列 , RabbitMQ 中的 Exchange .")],-1),x=(0,a._)("p",null,"生产者组中的生产者会向主题发送消息，而主题中存在多个队列，生产者每次生产消息之后是指定主题中的某个队列发送消息的。",-1),M=(0,a._)("ol",null,[(0,a._)("li",null,"Producer Group 生产者组：代表某一类的生产者，比如有多个秒杀系统作为生产者，这多个合在一起就是一个 Producer Group 生产者组，它们一般生产相同的消息。"),(0,a._)("li",null,"Consumer Group 消费者组：代表某一类的消费者，比如有多个短信系统作为消费者，这多个合在一起就是一个 Consumer Group 消费者组，它们一般消费相同的消息。"),(0,a._)("li",null,"Topic 主题：代表一类消息，比如订单消息，物流消息等等。")],-1),Q=(0,a._)("p",null,"每个主题中都有多个队列 (分布在不同的 Broker 中，如果是集群的话，Broker 又分布在不同的服务器中), 集群消费模式下，一个消费者集群多台机器共同消费一个 topic 的多个队列，一个队列只会被一个消费者消费。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。所以一般要控制消费者组中的消费者个数和主题中队列个数相同 .",-1),R=(0,a._)("h3",{id:"_1-1-2-每个消费者组在每个队列上维护一个消费位置-为什么呢",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-1-2-每个消费者组在每个队列上维护一个消费位置-为什么呢","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.1.2. 每个消费者组在每个队列上维护一个消费位置 , 为什么呢？")],-1),q=(0,a._)("p",null,[(0,a._)("img",{src:o,alt:"picture 2"}),(0,a._)("br"),(0,a._)("img",{src:t,alt:"picture 3"})],-1),U=(0,a._)("p",null,"在发布订阅模式中一般会涉及到多个消费者组，而每个消费者组在每个队列中的消费位置都是不同的。如果此时有多个消费者组，那么消息被一个消费者组消费完之后是不会删除的，因为其它消费者组也需要消费，它仅仅是为每个消费者组维护一个消费位移 (offset), 每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。",-1),C=(0,a._)("h3",{id:"_1-1-3-为什么一个主题中需要维护多个队列",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-1-3-为什么一个主题中需要维护多个队列","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.1.3. 为什么一个主题中需要维护多个队列 ?")],-1),S=(0,a._)("p",null,[(0,a._)("img",{src:i,alt:"picture 4"})],-1),N=(0,a._)("p",null,"是为了提高并发能力",-1),P=(0,a._)("p",null,"如果每个主题中只存在一个队列，这个队列中也维护着每个消费者组的消费位置，虽然这样也可以做到发布订阅模式，但是，这样生产者只能向一个队列发送消息，又因为需要维护消费位置所以一个队列只能对应一个消费者组中的消费者，这样其他的消费者就无法工作，并发度一下子就小了很多。",-1),T=(0,a._)("p",null,"所以总结来说，RocketMQ 通过使用在一个 Topic 中配置多个队列并且每个队列维护每个消费者组的消费位置，实现了主题模式/发布订阅模式 .",-1),A=(0,a._)("h2",{id:"_1-2-rocketmq-的架构图",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-2-rocketmq-的架构图","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.2. RocketMQ 的架构图")],-1),I=(0,a._)("p",null,[(0,a._)("img",{src:_,alt:"picture 2"})],-1),y=(0,a._)("p",null,"RocketMQ 技术架构中有四大角色 NameServer, Broker, Producer, Consumer",-1),H=(0,a._)("h3",{id:"_1-2-1-broker",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-2-1-broker","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.2.1. Broker")],-1),D=(0,a._)("p",null,[(0,a._)("img",{src:u,alt:"picture 5"})],-1),G=(0,a._)("p",null,"主要负责消息的存储，投递和查询以及服务高可用保证。说白了就是消息队列服务器嘛，生产者生产消息到 Broker , 消费者从 Broker 拉取消息并消费。",-1),K=(0,a._)("p",null,"一个 Topic 中存在多个队列。一个 Topic 分布在多个 Broker 上，一个 Broker 可以配置多个 Topic，它们是多对多的关系。",-1),w=(0,a._)("p",null,"如果某个 Topic 消息量很大，应该给它多配置几个队列以提高并发能力，并且尽量多分布在不同 Broker 上，以减轻某个 Broker 的压力",-1),F=(0,a._)("p",null,"Topic 消息量都比较均匀的情况下，如果某个 broker 上的队列越多，则该 broker 压力越大。",-1),L=(0,a._)("h3",{id:"_1-2-2-nameserver",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-2-2-nameserver","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.2.2. NameServer")],-1),Y=(0,a._)("p",null,"注册中心，主要提供两个功能: Broker 管理 和路由信息管理. Broker 会将信息注册到 NameServer 中，此时 NameServer 就存放了很多 Broker 的信息 (Broker 的路由表), 消费者和生产者就从 NameServer 中获取路由表然后照着路由表的信息和对应的 Broker 进行通信",-1),Z=(0,a._)("h3",{id:"_1-2-3-producer",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-2-3-producer","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.2.3. Producer")],-1),E=(0,a._)("p",null,"生产者，消息发布的角色，支持分布式集群方式部署。",-1),O=(0,a._)("h3",{id:"_1-2-4-consumer",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-2-4-consumer","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.2.4. Consumer")],-1),J=(0,a._)("p",null,"消费者，消息消费的角色，支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。",-1),j=(0,a._)("h3",{id:"_1-2-5-架构原理",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-2-5-架构原理","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.2.5. 架构原理")],-1),z=(0,a._)("p",null,[(0,a._)("img",{src:c,alt:"picture 6"}),(0,a._)("br"),(0,a._)("img",{src:s,alt:"picture 7"})],-1),V=(0,a._)("ol",null,[(0,a._)("li",null,[(0,a._)("p",null,"Broker 做了集群并且还进行了主从部署，由于消息分布在各个 Broker 上，一旦某个 Broker 宕机，则该 Broker 上的消息读写都会受到影响。所以 Rocketmq 提供了 master/slave 的结构，salve 定时从 master 同步数据 (同步刷盘或者异步刷盘), 如果 master 宕机，则 slave 提供消费服务，但是不能写入消息")]),(0,a._)("li",null,[(0,a._)("p",null,"为了保证 HA, NameServer 也做了集群部署，但是请注意它是去中心化的。也就意味着它没有主节点，你可以很明显地看出 NameServer 的所有节点是没有进行 Info Replicate 的，在 RocketMQ 中是通过单个 Broker 和所有 NameServer 保持长连接，并且在每隔 30 秒 Broker 会向所有 Nameserver 发送心跳，心跳包含了自身的 Topic 配置信息，这个步骤就对应这上面的 Routing Info."),(0,a._)("blockquote",null,[(0,a._)("p",null,"HA 机制：为了提高消息消费的高可用性，避免 Broker 发生单点故障引起存储在 Broker 上的消息无法及时消费，RocketMQ 引入了 Broker 主备机制，即消息消费到达主服务器后需要将消息同步到消息从服务器，如果主服务器 Broker 宕机后，消息消费者可以从从服务器拉取消息。")])]),(0,a._)("li",null,[(0,a._)("p",null,"在生产者需要向 Broker 发送消息的时候，需要先从 NameServer 获取关于 Broker 的路由信息，然后通过轮询的方法去向每个队列中生产数据以达到负载均衡的效果。")]),(0,a._)("li",null,[(0,a._)("p",null,"消费者通过 NameServer 获取所有 Broker 的路由信息后，向 Broker 发送 Pull 请求来获取消息数据。")])],-1),W=(0,a._)("h2",{id:"_1-3-如何解决顺序消费-重复消费",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-3-如何解决顺序消费-重复消费","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.3. 如何解决顺序消费，重复消费")],-1),X=(0,a._)("blockquote",null,[(0,a._)("p",null,"Kafka 的架构基本和 RocketMQ 类似，只是它注册中心使用了 Zookeeper，它的分区就相当于 RocketMQ 中的队列")],-1),$=(0,a._)("h3",{id:"_1-3-1-顺序消费",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-3-1-顺序消费","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.3.1. 顺序消费")],-1),ee=(0,a._)("p",null,[(0,a._)("img",{src:d,alt:"picture 8"}),(0,a._)("br"),(0,a.Uk)(" RocketMQ 在主题上是无序的，它只有在队列层面才是保证有序的。")],-1),re=(0,a._)("p",null,"Producer 生产消息的时候会进行轮询来向同一主题的不同消息队列发送消息。那么如果此时有几个消息分别是同一个订单的创建，支付，发货，在轮询的策略下这三个消息会被发送到不同队列 , 因为在不同的队列此时就无法使用 RocketMQ 带来的队列有序特性来保证消息有序性了。",-1),le=(0,a._)("blockquote",null,[(0,a._)("p",null,"轮询是按照某种负载均衡策略的算法进行顺序触发，轮询时会保存当前执行后的索引，以便于下次执行时可以拿到开始索引位置，以达到负载均衡的目的。")],-1),ae=(0,a._)("h4",{id:"_1-3-1-1-rocketmq-实现顺序消费",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-3-1-1-rocketmq-实现顺序消费","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.3.1.1. rocketmq 实现顺序消费")],-1),ne=(0,a._)("blockquote",null,[(0,a._)("p",null,"顺序消息在日常的功能场景中很常见，比如点外卖生成外卖订单，付款，送餐的消息需要保证严格的顺序。")],-1),oe=(0,a._)("p",null,"消息队列为了保证高并发，一般会配置多个分区，并支持多个客户端同时消费，因此只能保证分区内有序。",-1),te=(0,a._)("p",null,"要保证一个订单有关的消息顺序消费，有两点需要注意，一是将订单有关的消息发送到相关 Topic 中同一个 queue 里，二是消费者按照先进先出的原则进行消费。",-1),ie=(0,a._)("ol",null,[(0,a._)("li",null,[(0,a._)("p",null,"全局顺序消息：RocketMQ 如果要保证全局顺序消息的话需要在生产端只保留一个读写队列，然后消费端只有一个消费线程，这样会降低 RocketMQ 的高可用和高吞吐量。")]),(0,a._)("li",null,[(0,a._)("p",null,"分区顺序消息：分区顺序消息同样需要生产端和消费端配合，生产端根据同一个订单 ID 把消息路由到同一个 MessageQueue，消费端控制从同一个 MessageQueue 取出的消息不被并发处理。")])],-1),_e=(0,a._)("h3",{id:"_1-3-2-重复消费-幂等",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-3-2-重复消费-幂等","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.3.2. 重复消费 (幂等)")],-1),ue=(0,a._)("p",null,"幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。也就是对同一个消息的处理结果，执行多少次都不变。",-1),ce=(0,a._)("h4",{id:"_1-3-2-1-那么如何给业务实现幂等呢",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-3-2-1-那么如何给业务实现幂等呢","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.3.2.1. 那么如何给业务实现幂等呢？")],-1),se=(0,a._)("p",null,"只要处理消息之前先根据业务判断一下本次操作是否已经执行过了，如果已经执行过了，那就不再执行了，这样就可以保证消费者的幂等性。",-1),de=(0,a._)("p",null,"比如每条消息都会有一条唯一的消息 msgId，消费者接收到消息会存储消息日志，如果日志中存在相同 ID 的消息，就证明这条消息已经被处理过了。可以使用写入 Redis 来保证，因为 Redis 的 key 和 value 就是天然支持幂等的。当然还有使用数据库插入法 , 基于数据库的唯一键来保证重复数据不会被插入多条。",-1),he=(0,a._)("h2",{id:"_1-4-rocketmq-如何保证消息不丢失",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-4-rocketmq-如何保证消息不丢失","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.4. rocketmq 如何保证消息不丢失")],-1),ke=(0,a._)("p",null,[(0,a._)("img",{src:h,alt:"picture 13"})],-1),pe=(0,a._)("ol",null,[(0,a._)("li",null,"生产阶段，Producer 新建消息，然后通过网络将消息投递给 MQ Broker"),(0,a._)("li",null,"存储阶段，消息将会存储在 Broker 端磁盘中"),(0,a._)("li",null,"消息阶段，Consumer 将会从 Broker 拉取消息")],-1),me=(0,a._)("h3",{id:"_1-4-1-从-producer-分析-如何确保消息正确的发送到了-broker",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-4-1-从-producer-分析-如何确保消息正确的发送到了-broker","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.4.1. 从 Producer 分析：如何确保消息正确的发送到了 Broker?")],-1),ge=(0,a._)("ol",null,[(0,a._)("li",null,"默认情况下，可以通过同步的方式阻塞式的发送，check SendStatus，状态是 OK，表示消息一定成功的投递到了 Broker，状态超时或者失败，则会触发默认的 2 次重试。此方法的发送结果，可能 Broker 存储成功了，也可能没成功"),(0,a._)("li",null,"采取事务消息的投递方式，并不能保证消息 100% 投递成功到了 Broker，但是如果消息发送 Ack 失败的话，此消息会存储在 CommitLog 当中，但是对 ConsumerQueue 是不可见的。可以在日志中查看到这条异常的消息，严格意义上来讲，也并没有完全丢失"),(0,a._)("li",null,"RocketMQ 支持 日志的索引，如果一条消息发送之后超时，也可以通过查询日志的 API，来 check 是否在 Broker 存储成功")],-1),be=(0,a._)("h3",{id:"_1-4-2-从-broker-分析-如果确保接收到的消息不会丢失",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-4-2-从-broker-分析-如果确保接收到的消息不会丢失","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.4.2. 从 Broker 分析：如果确保接收到的消息不会丢失？")],-1),fe=(0,a._)("ol",null,[(0,a._)("li",null,"消息支持持久化到 Commitlog 里面，即使宕机后重启，未消费的消息也是可以加载出来的"),(0,a._)("li",null,"Broker 自身支持同步刷盘，异步刷盘的策略，可以保证接收到的消息一定存储在本地的内存中"),(0,a._)("li",null,"Broker 集群支持 1 主 N 从的策略，支持同步复制和异步复制的方式，同步复制可以保证即使 Master 磁盘崩溃，消息仍然不会丢失")],-1),Be=(0,a._)("h3",{id:"_1-4-3-从-cunmser-分析-如何确保拉取到的消息被成功消费",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-4-3-从-cunmser-分析-如何确保拉取到的消息被成功消费","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.4.3. 从 Cunmser 分析：如何确保拉取到的消息被成功消费？")],-1),ve=(0,a._)("ol",null,[(0,a._)("li",null,"消费者可以根据自身的策略批量 Pull 消息"),(0,a._)("li",null,"Consumer 自身维护一个持久化的 offset , 标记已经成功消费或者已经成功发回到 broker 的消息下标"),(0,a._)("li",null,"如果 Consumer 消费失败，那么它会把这个消息发回给 Broker，发回成功后，再更新自己的 offset"),(0,a._)("li",null,"如果 Consumer 消费失败，发回给 broker 时，broker 挂掉了，那么 Consumer 会定时重试这个操作"),(0,a._)("li",null,"如果 Consumer 和 broker 一起挂了，消息也不会丢失，因为 consumer 里面的 offset 是定时持久化的，重启之后，继续拉取 offset 之前的消息到本地")],-1),xe=(0,a._)("h2",{id:"_1-5-消息堆积问题-削峰",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-5-消息堆积问题-削峰","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.5. 消息堆积问题 (削峰)")],-1),Me=(0,a._)("p",null,"产生消息堆积的根源其实就只有两个：生产者生产太快或者消费者消费太慢。",-1),Qe=(0,a._)("ol",null,[(0,a._)("li",null,"当流量到峰值的时候是因为生产者生产太快，可以使用一些限流降级的方法，当然也可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。"),(0,a._)("li",null,"如果消费者消费过慢的话，可以先检查是否是消费者出现了大量的消费错误，或者打印一下日志查看是否是哪一个线程卡死，出现了锁资源不释放等等的问题。")],-1),Re=(0,a._)("h3",{id:"_1-5-1-解决消息堆积问题的方法",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-5-1-解决消息堆积问题的方法","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.5.1. 解决消息堆积问题的方法")],-1),qe=(0,a._)("p",null,[(0,a._)("img",{src:k,alt:"picture 9"})],-1),Ue=(0,a._)("p",null,"最快速解决消息堆积问题的方法还是增加消费者实例，同时需要增加每个主题的队列数量，在 RocketMQ 中，一个队列只会被一个消费者消费",-1),Ce=(0,a._)("h2",{id:"_1-6-回溯消费",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-6-回溯消费","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.6. 回溯消费")],-1),Se=(0,a._)("p",null,"回溯消费是指 Consumer 已经消费成功的消息，由于业务上需求需要重新消费，在 RocketMQ 中，Broker 在向 Consumer 投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于 Consumer 系统故障，恢复后需要重新消费 1 小时前的数据，那么 Broker 要提供一种机制，可以按照时间维度来回退消费进度. RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒。",-1),Ne=(0,a._)("h2",{id:"_1-7-rocketmq-的刷盘机制",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-7-rocketmq-的刷盘机制","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.7. RocketMQ 的刷盘机制")],-1),Pe=(0,a._)("p",null,"RocketMQ 需要将消息存储到磁盘上，这样才能保证断电后消息不会丢失。同时这样才可以让存储的消息量可以超出内存的限制. RocketMQ 为了提高性能，会尽量保证磁盘的顺序写。消息在写入磁盘时，有两种写磁盘的方式，同步刷盘和异步刷盘",-1),Te=(0,a._)("h3",{id:"_1-7-1-同步刷盘和异步刷盘",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-7-1-同步刷盘和异步刷盘","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.7.1. 同步刷盘和异步刷盘")],-1),Ae=(0,a._)("p",null,[(0,a._)("img",{src:p,alt:"picture 10"})],-1),Ie=(0,a._)("p",null,"在同步刷盘中需要等待一个刷盘成功的 ACK , 同步刷盘对 MQ 消息可靠性来说是一种不错的保障，但是性能上会有较大影响 , 一般地适用于金融等特定业务场景。",-1),ye=(0,a._)("p",null,"而异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟 , 提高了 MQ 的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景。",-1),He=(0,a._)("p",null,"一般地，异步刷盘只有在 Broker 意外宕机的时候会丢失部分数据，你可以设置 Broker 的参数 FlushDiskType 来调整你的刷盘策略 (ASYNC_FLUSH 或者 SYNC_FLUSH).",-1),De=(0,a._)("h3",{id:"_1-7-2-同步复制和异步复制",tabindex:"-1"},[(0,a._)("a",{class:"header-anchor",href:"#_1-7-2-同步复制和异步复制","aria-hidden":"true"},"#"),(0,a.Uk)(" 1.7.2. 同步复制和异步复制")],-1),Ge=(0,a._)("p",null,"同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 Borker 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。",-1),Ke=(0,a._)("ol",null,[(0,a._)("li",null,"同步复制 (同步双写): 只有消息同步双写到主从结点上时才返回写入成功。"),(0,a._)("li",null,"异步复制：消息写入主节点之后就直接返回写入成功。")],-1),we={},Fe=(0,l(3744).Z)(we,[["render",function(e,r){return(0,a.wg)(),(0,a.iD)(a.HY,null,[m,g,b,f,B,v,x,M,Q,R,q,U,C,S,N,P,T,A,I,y,H,D,G,K,w,F,L,Y,Z,E,O,J,j,z,V,W,X,$,ee,re,le,ae,ne,oe,te,ie,_e,ue,ce,se,de,he,ke,pe,me,ge,be,fe,Be,ve,xe,Me,Qe,Re,qe,Ue,Ce,Se,Ne,Pe,Te,Ae,Ie,ye,He,De,Ge,Ke],64)}]])},3744:(e,r)=>{r.Z=(e,r)=>{const l=e.__vccOpts||e;for(const[e,a]of r)l[e]=a;return l}},553:(e,r,l)=>{e.exports=l.p+"assets/img/1640782980495.24ed4686.png"},7716:(e,r,l)=>{e.exports=l.p+"assets/img/1640783109549.4ba0e824.png"},8086:(e,r,l)=>{e.exports=l.p+"assets/img/1640783132410.26bd946a.png"},4637:(e,r,l)=>{e.exports=l.p+"assets/img/1640783258664.13d27d10.png"},3400:(e,r,l)=>{e.exports=l.p+"assets/img/1640783496770.2e6692b4.png"},9141:(e,r,l)=>{e.exports=l.p+"assets/img/1640784014853.530f22ca.png"},8354:(e,r,l)=>{e.exports=l.p+"assets/img/1640784132338.c35c619d.png"},9324:(e,r,l)=>{e.exports=l.p+"assets/img/1640784781993.21618f8b.png"},3900:(e,r,l)=>{e.exports=l.p+"assets/img/1640785182444.24ed4686.png"},2128:(e,r,l)=>{e.exports=l.p+"assets/img/1640785263729.5c672570.png"},3333:(e,r,l)=>{e.exports=l.p+"assets/img/1641168972003.f45efa2e.png"},9480:(e,r,l)=>{e.exports=l.p+"assets/img/1645065986123.8fa876a8.png"}}]);